# Capa B: Enlazador Sem√°ntico

## Responsabilidad

Detectar conexiones entre archivos que el an√°lisis est√°tico no puede ver, usando inteligencia artificial local y pattern matching.

Esta capa complementa la Capa A a√±adiendo "consciencia sem√°ntica".

---

## Tipos de Conexiones a Detectar

### 1. Estado Compartido
**Patr√≥n**: M√∫ltiples archivos leen/escriben el mismo objeto

```javascript
// store.js
export const state = { user: null };

// auth.js
state.user = { id: 1 }; // Escribe

// profile.js
console.log(state.user); // Lee
```

**Detecci√≥n**:
- Identificar objetos exportados mutables
- Rastrear archivos que importan ese objeto
- Marcar como "conectados por estado compartido"

---

### 2. Sistema de Eventos
**Patr√≥n**: Emisor y listeners sin import directo

```javascript
// button.js
eventBus.emit('click', data);

// analytics.js
eventBus.on('click', handler);
```

**Detecci√≥n**:
- Pattern matching: `emit`, `on`, `addEventListener`, `dispatch`
- Extraer nombres de eventos (strings literales)
- Agrupar archivos por eventos compartidos

---

### 3. Side Effects (Storage)
**Patr√≥n**: Comunicaci√≥n v√≠a localStorage, sessionStorage

```javascript
// writer.js
localStorage.setItem('token', value);

// reader.js
const token = localStorage.getItem('token');
```

**Detecci√≥n**:
- Buscar patrones: `localStorage.setItem/getItem`
- Extraer keys usadas
- Conectar writers y readers del mismo key

---

### 4. Configuraci√≥n Global
**Patr√≥n**: Constantes de config usadas en m√∫ltiples lugares

```javascript
// config.js
export const DEBUG = true;

// logger.js
if (DEBUG) console.log(...);
```

**Detecci√≥n**:
- Identificar archivos de configuraci√≥n
- Rastrear usos de esas constantes
- Marcar dependencias "de configuraci√≥n"

---

### 5. Archivos Desconectados (Shaders, CSS)
**Patr√≥n**: JS que configura un shader GLSL sin import

```javascript
// renderer.js
gl.uniform1f(location, 'u_zoom', zoom);

// shader.glsl
uniform float u_zoom;
```

**Detecci√≥n**:
- Buscar strings que coincidan con nombres en shaders
- Pattern matching: `uniform`, `attribute`, `varying`
- Conectar JS ‚Üî GLSL por nombres compartidos

---

## Componentes a Implementar

### 1. `pattern-matchers.js`
**Prop√≥sito**: Detectores heur√≠sticos para patrones comunes

**Funcionalidad**:
- `detectEventUsage()` - encuentra .emit() y .on()
- `detectStorageUsage()` - encuentra localStorage/sessionStorage
- `detectGlobalState()` - encuentra mutaciones de objetos importados
- `detectShaderUniforms()` - encuentra uniforms en GLSL y JS

**API**:
```javascript
function detectPatterns(code, filePath) {
  return {
    events: { emits: string[], listens: string[] },
    storage: { reads: string[], writes: string[] },
    globalMutations: string[],
    shaderUniforms: string[]
  };
}
```

**Stack T√©cnico**:
- Regex para patrones simples
- AST traversal para casos complejos

---

### 2. `llm-analyzer.js`
**Prop√≥sito**: Usar IA local para an√°lisis sem√°ntico profundo

**Funcionalidad**:
- Analizar c√≥digo con modelo local (Qwen2.5-Coder-7B)
- Hacer preguntas sobre conexiones no obvias
- Generar metadata sem√°ntica

**Prompt Template**:
```
Analiza este archivo y determina:
1. ¬øModifica alg√∫n estado global?
2. ¬øEmite o escucha eventos?
3. ¬øLee/escribe en localStorage?
4. ¬øQu√© otros archivos del proyecto podr√≠an verse afectados si modifico este?

Archivo: {filePath}
C√≥digo: {code}
Contexto: {systemMap}

Responde en JSON:
{
  "sharedState": ["store.userState"],
  "events": { "emits": ["user:login"], "listens": ["app:ready"] },
  "sideEffects": ["localStorage.token"],
  "affectedFiles": ["Dashboard.js", "AuthService.js"],
  "reasoning": "Explica por qu√© est√°n conectados"
}
```

**Stack T√©cnico**:
- Ollama para ejecutar modelos locales
- Qwen2.5-Coder-7B (modelo peque√±o y r√°pido)
- JSON parsing de respuestas

---

### 3. `enricher.js`
**Prop√≥sito**: Combinar resultados de pattern-matchers + LLM + Capa A

**Funcionalidad**:
- Tomar `system-map.json` (Capa A)
- A√±adir metadata sem√°ntica de pattern-matchers
- A√±adir insights de LLM
- Generar `enhanced-system-map.json`

**API**:
```javascript
async function enrichGraph(staticGraph, projectPath) {
  // 1. Para cada archivo, ejecutar pattern matchers
  // 2. Para archivos cr√≠ticos, ejecutar LLM
  // 3. Combinar resultados
  // 4. Retornar enhanced graph
}
```

**Output**:
```typescript
interface EnhancedFileNode extends FileNode {
  semanticConnections: {
    sharedState: string[];
    events: { emits: string[]; listens: string[] };
    storage: { reads: string[]; writes: string[] };
  };
  affectedBy: string[]; // Archivos que afectan a este
  affects: string[];    // Archivos que este afecta
  riskLevel: 'low' | 'medium' | 'high';
  reasoning: string;    // Por qu√© est√° conectado (del LLM)
}
```

---

### 4. `connection-inference.js`
**Prop√≥sito**: Inferir conexiones a partir de patterns detectados

**Funcionalidad**:
- Si fileA emite evento 'X' y fileB escucha 'X' ‚Üí conectarlos
- Si fileA escribe key 'token' y fileB lee 'token' ‚Üí conectarlos
- Si fileA y fileB ambos modifican state.user ‚Üí conectarlos

**Algoritmo**:
```javascript
function inferConnections(patterns) {
  const connections = [];

  // Conectar por eventos
  for (const emitter of findEmitters('click')) {
    for (const listener of findListeners('click')) {
      connections.push({
        from: emitter,
        to: listener,
        type: 'event',
        event: 'click'
      });
    }
  }

  // Conectar por storage
  // Conectar por estado
  // ...

  return connections;
}
```

---

## Estrategia de Implementaci√≥n

### Fase 1: Pattern Matchers (Sin IA)
**Objetivo**: Detectar patrones sin usar LLM

**Implementar**:
1. Detector de eventos (emit/on)
2. Detector de localStorage
3. Detector de estado mutable

**Validar con**: `test-cases/scenario-2-shared-state/`, `scenario-3-event-system/`

---

### Fase 2: LLM Local (Opcional)
**Objetivo**: A√±adir inteligencia para casos complejos

**Consideraciones**:
- ¬øVale la pena el costo computacional?
- ¬øQwen2.5-Coder-7B es suficientemente bueno?
- ¬øAlternativa: GPT-4o-mini v√≠a API?

**Decisi√≥n**: Implementar solo si pattern matchers no son suficientes

---

### Fase 3: Enriquecimiento
**Objetivo**: Combinar Capa A + Capa B

**Output**: `enhanced-system-map.json` listo para Capa C

---

## Casos de Prueba

**Validar con**:
- `test-cases/scenario-2-shared-state/` - Estado compartido
- `test-cases/scenario-3-event-system/` - Eventos
- `test-cases/scenario-4-side-effect/` - localStorage
- `test-cases/scenario-5-disconnected-shader/` - Shaders

**Criterio de √©xito**:
- Detecta conexiones que Capa A no ve
- Tasa de falsos positivos < 10%
- Tasa de falsos negativos < 5%

---

## Limitaciones

**Lo que la Capa B NO puede hacer perfectamente**:

1. **C√≥digo din√°mico extremo**: `eval()`, `new Function()`
2. **L√≥gica de negocio difusa**: "Esta funci√≥n afecta indirectamente a aquella por razones de negocio"
3. **Dependencias externas**: APIs, bases de datos

**Soluci√≥n**: Advertir al usuario que hay incertidumbre

---

## Performance

**Objetivo**: Analizar 100 archivos en < 30 segundos (sin LLM)

**Optimizaciones**:
- Pattern matching primero (r√°pido)
- LLM solo para casos ambiguos (lento)
- Cach√© de resultados de LLM

---

## Configuraci√≥n del LLM

### Implementaci√≥n Actual ‚úÖ

**llama-server (Local - Implementado)**
- Servidor local con LFM2.5-1.2B-Instruct
- Binarios optimizados con Vulkan (GPU) y CPU
- Continuous batching para paralelismo
- Ver [src/ai/README.md](../ai/README.md) para setup completo

**Configuraci√≥n**:
```bash
# Iniciar servidor
OmnySys ai start gpu

# Habilitar en config
# Editar src/ai/ai-config.json: "enabled": true

# Analizar con LLM
OmnySys analyze /path/to/project
```

### Alternativas (No implementadas)

**Opci√≥n A: Ollama (Local)**
```bash
ollama pull qwen2.5-coder:7b
ollama run qwen2.5-coder:7b
```

**Opci√≥n B: OpenAI API (Cloud)**
```javascript
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const response = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [{ role: 'user', content: prompt }]
});
```

---

## Estado de Implementaci√≥n

### ‚úÖ Implementado

1. **pattern-matchers.js** - Detecci√≥n est√°tica de patrones (eventos, storage, CSS)
2. **llm-analyzer.js** - Wrapper para an√°lisis LLM local
3. **semantic-enricher.js** - Orquestador static + LLM
4. **schema-validator.js** - Validaci√≥n de resultados
5. **Integraci√≥n con indexer.js** - Pipeline completo

### ‚è≠Ô∏è Pendiente (Opcional)

1. **connection-inference.js** - Inferencia avanzada de conexiones
   - Actualmente se hace en shared-state-detector y event-pattern-detector
2. **Fallback a OpenAI API** - Si servidor local falla
3. **Cach√© de resultados LLM** - Para evitar re-an√°lisis

---

## Uso

### An√°lisis B√°sico (Solo Static)

```bash
# LLM deshabilitado por defecto
OmnySys analyze /path/to/project
```

Usa solo:
- Pattern matching (regex)
- AST traversal
- Heur√≠sticas est√°ticas

**Ventajas**: Instant√°neo, zero costo
**Limitaciones**: No detecta indirecci√≥n ni c√≥digo din√°mico

### An√°lisis Avanzado (Static + LLM)

```bash
# 1. Habilitar LLM en config
# Editar src/ai/ai-config.json: "enabled": true

# 2. Iniciar servidor
OmnySys ai start gpu

# 3. Analizar
OmnySys analyze /path/to/project
```

Output:
```
ü§ñ LLM enrichment phase...
üìä Analyzing 12 complex files with LLM...
‚úì Enhanced 10/12 files with LLM insights
```

**Ventajas**: Detecta casos complejos, indirecci√≥n, razonamiento contextual
**Limitaciones**: M√°s lento (200-500ms por archivo), requiere recursos

### ¬øCu√°ndo Usar LLM?

LLM se activa autom√°ticamente solo para:
1. **C√≥digo din√°mico**: `window[prop] = value`, `eval()`
2. **Baja confianza**: Patrones ambiguos detectados por static
3. **Complejidad alta**: >3 eventos, >3 shared state writes

Configurar en `src/ai/ai-config.json`:
```json
{
  "analysis": {
    "llmOnlyForComplex": true,  // Solo casos complejos
    "complexityThreshold": 0.7,
    "confidenceThreshold": 0.8
  }
}
```

---

## Siguientes Pasos

1. ‚úÖ Validar con test-cases existentes
2. ‚úÖ Transferir archivos de Giteach (binarios + modelo)
3. ‚è≠Ô∏è Crear test-cases espec√≠ficos para LLM (c√≥digo din√°mico, indirecci√≥n)
4. ‚è≠Ô∏è Benchmark de performance (GPU vs CPU)
5. ‚è≠Ô∏è Fine-tuning de prompts para mejor precisi√≥n

---

## Referencias

- [src/ai/README.md](../ai/README.md) - Setup completo de AI
- [../ai/llm-client.js](../ai/llm-client.js) - Cliente HTTP
- [llm-analyzer.js](llm-analyzer.js) - Implementaci√≥n del analyzer
- [semantic-enricher.js](semantic-enricher.js) - Orquestador
- [docs/ai_architecture/AI_SETUP_GUIDE.md](../../docs/ai_architecture/AI_SETUP_GUIDE.md) - Arquitectura Vulkan
