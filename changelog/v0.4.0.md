# CHANGELOG - OmnySys

## [0.4.0] - 2026-03-02

### Added - Phase 3.8: Capa B - Semantic Enrichment (COMPLETE ✓)

#### Hybrid AI Architecture (80/20 Rule)
**Strategic Pivot**: Scripts for 80%, AI for 20% complex cases only
- **Before**: Phase 5 would use AI for ALL semantic detection
- **After**: Phase 3.8 uses scripts for 80%, AI for 20% (complex cases only)

**Rationale**:
- ✅ Scripts CAN detect patterns like `window.gameState`, `eventBus.on()`
- ✅ Scripts are instant (<200ms), zero cost, 100% reproducible
- ⚠️ AI needed only for: indirection, dynamic code, context understanding
- ⚠️ Using AI for everything is overkill (200s vs 30s for 100 files)

**Performance Impact**:
```
100 files project:

ALL AI (original plan):
- Time: 200s (2s per file)
- Cost: Model inference for all files

HYBRID (new plan):
- Static: 4s (all files)
- AI: 20s (10 complex files only)
- Total: 24s
- Savings: 88% faster
```

#### Core Components Implemented

1. **static-extractors.js** (300+ lines)
   - **localStorage/sessionStorage detection**: Detects read/write operations
   - **Event pattern detection**: Detects addEventListener, emit, dispatchEvent
   - **Global variable access**: Detects window.*, global.*, globalThis.*
   - **Advanced pattern extractors**: Web Workers, BroadcastChannel, WebSocket, SSE
   - **Multi-file analysis**: `detectAllSemanticConnections()` for cross-file connections

2. **llm-analyzer.js** (350+ lines)
   - **Local LLM integration**: Wrapper for llama-server with GPU/CPU
   - **Smart file selection**: Only analyzes files with complexity indicators
   - **Context-aware prompting**: Uses project metadata to guide analysis
   - **Caching system**: Avoids re-analysis of unchanged files
   - **Confidence filtering**: Filters results with low confidence

3. **semantic-enricher.js** (400+ lines)
   - **Orchestration engine**: Combines static + LLM analysis
   - **Iterative consolidation**: Iterative mode until convergence
   - **Enhanced connections**: Semantic connections with confidence and reasoning
   - **Risk assessment**: Risk evaluation based on complexity
   - **Statistics tracking**: Analysis metrics and improvements

4. **semantic-issues-detector.js** (300+ lines)
   - **Orphaned files detection**: Orphaned files with side effects (suspicious)
   - **Unhandled events**: Events emitted but without listeners (possible error)
   - **Undefined shared state**: State read but never written (undefined)
   - **Dead shared state**: State written but never read (dead code)
   - **Connection hotspots**: Files with high connection complexity
   - **Suspicious patterns**: Patterns requiring manual review

5. **schema-validator.js** (200+ lines)
   - **JSON Schema validation**: Validates output against formal schema
   - **Confidence filtering**: Filters connections with low confidence
   - **Type validation**: Validates data types and structures
   - **Quality control**: Generates warnings for detected issues

#### Semantic Connection Types Detected

1. **Shared State** (localStorage/sessionStorage)
   ```javascript
   // writer.js
   localStorage.setItem('token', value);
   
   // reader.js  
   const token = localStorage.getItem('token');
   ```

2. **Event Listeners** (addEventListener, emit, dispatchEvent)
   ```javascript
   // emitter.js
   eventBus.emit('user:login', data);
   
   // listener.js
   eventBus.on('user:login', handler);
   ```

3. **Global Access** (window.*, global.*, globalThis.*)
   ```javascript
   // writer.js
   window.gameState = { score: 0 };
   
   // reader.js
   console.log(window.gameState.score);
   ```

4. **Advanced Patterns** (Web Workers, BroadcastChannel, WebSocket)
   ```javascript
   // worker.js
   self.postMessage({ type: 'update', data });
   
   // main.js
   worker.postMessage({ type: 'init' });
   ```

#### AI Integration Features

- **Local LLM Support**: Qwen2.5-Coder-7B with GPU acceleration
- **Smart Caching**: Cache key based on code + prompt to avoid re-analysis
- **Context Limiting**: Prompt size limited to 50KB to prevent hallucinations
- **Confidence Thresholds**: Filtering by confidence (configurable 0.7-0.9)
- **Iterative Mode**: Re-analysis until no improvements (with safety limit)

#### Configuration System

```javascript
// ai-config.json
{
  "llm": {
    "enabled": true,
    "mode": "gpu",
    "confidenceThreshold": 0.8,
    "analyzePercentage": 1.0
  },
  "analysis": {
    "llmOnlyForComplex": true,
    "complexityThreshold": 0.7,
    "confidenceThreshold": 0.8,
    "enableLLMCache": true
  },
  "prompts": {
    "analysisTemplate": "Analyze this file and determine: 1. Shared state usage 2. Event patterns 3. Side effects 4. Affected files..."
  }
}
```

#### Production Ready Features

- **MCP Server Integration**: `mcp-server.js` exposes tools to Claude Code
- **Auto LLM Startup**: Automatically starts GPU/CPU servers
- **Memory Management**: Efficient caching and memory usage
- **Error Handling**: Robust error handling and fallbacks
- **Performance Monitoring**: Real-time performance metrics

#### Test Cases & Validation

- **scenario-2-semantic**: 6 files with semantic connections (no static imports)
- **scenario-4-localStorage-bridge**: localStorage bridge patterns
- **scenario-5-shader-bridge**: GLSL/JS shader connections
- **Advanced pattern tests**: Web Workers, BroadcastChannel, WebSocket

#### Benefits for AI Editors

1. **Context Awareness**: AI understands hidden connections
2. **Risk Assessment**: Automatic risk scoring for changes
3. **Impact Analysis**: Know what files are affected before editing
4. **Issue Detection**: Find problems AI might miss
5. **Performance**: Instant results with smart caching

#### Production Deployment

- **CLI Ready**: `node src/layer-c-memory/mcp-server.js /path/to/project`
- **Auto-Configuration**: Detects project structure and configures automatically
- **Background Operation**: File watcher updates graph automatically
- **MCP Protocol**: Full integration with Claude Code and other AI tools

#### Version Bump: 0.3.4 → 0.4.0

This represents a major milestone with complete semantic analysis capability, production-ready MCP server, and hybrid AI architecture that delivers enterprise-grade performance.

---

## [0.4.1] - 2026-02-03 (In Progress)

### Added - Phase 3.9: Advanced Extractors & Refactoring

#### New Extractors (5 Additional Tunnel Vision Cases)

1. **metadata-extractors.js** - JSDoc, Async Patterns, Error Handling, Build Flags
   - `extractJSDocContracts()`: Parses @param, @returns, @throws, @deprecated, @async
   - `extractAsyncPatterns()`: Detects async/await, Promise.all/race, timeouts, intervals
   - `extractErrorHandling()`: try/catch, throw statements, error codes, custom errors
   - `extractBuildTimeDependencies()`: __DEV__, process.env.NODE_ENV flags
   - **18/30 tunnel vision cases now detected**

2. **css-in-js-extractor.js** - CSS-in-JS Pattern Detection
   - `extractStyledComponents()`: styled-components template literals
   - `extractThemeUsage()`: props.theme dependencies
   - Detects cross-file theme dependencies that static imports miss

3. **typescript-extractor.js** - TypeScript Interface Dependencies
   - `extractTypeDefinitions()`: interface, type aliases
   - `extractInterfaceImplementations()`: implements clauses
   - Detects breaking changes in shared interfaces

4. **redux-context-extractor.js** - Redux & React Context
   - `extractReduxSelectors()`: useSelector hook dependencies
   - `extractReduxActions()`: useDispatch, action creators
   - `extractContextUsage()`: useContext, Context.Consumer patterns

#### Semantic-Enricher Refactoring

**Before**: Single file `semantic-enricher.js` (820+ lines)

**After**: Modular architecture in `enricher/` directory:
```
src/layer-b-semantic/enricher/
├── index.js              # Public API (re-exports)
├── core.js               # Main enrichSemanticAnalysis() function
├── mergers.js            # Analysis merging functions
├── context-builders.js   # File & project context builders
└── utils.js              # Utilities (limitContextSize, getEnrichmentStats)
```

**Benefits**:
- ✅ Each module < 400 lines (maintainable)
- ✅ Clear separation of concerns
- ✅ Easier testing of individual functions
- ✅ Backward compatible (original file re-exports from new modules)

#### LLM Prompt Enhancement

**Metadata now included in prompts**:
```javascript
// LLM now receives:
- JSDoc contracts (@param, @returns, @deprecated, etc.)
- Async patterns (async/await, Promise.all, timeouts)
- Error handling (try/catch, custom errors)
- Build flags (__DEV__, process.env.NODE_ENV)
- CSS-in-JS connections (styled-components themes)
- Redux/Context usage (selectors, actions)
```

This allows the LLM to:
1. Validate JSDoc contracts against actual implementation
2. Understand async boundaries and error propagation
3. Detect build-time conditional code
4. Identify theme/styling dependencies
5. Trace Redux data flow

#### CLI `check` Command

New command for pre-edit impact analysis:
```bash
omnysystem check src/file.js
```

Shows:
- File metrics (imports, exports, dependencies)
- JSDoc contracts
- Side effects (localStorage, global access)
- Breaking change risks
- Semantic connections (events, shared state)
- AI recommendations

#### Cache System Enhancement

- Moved from `.aver/` to `.OmnySystemData/` (consistent with project structure)
- MD5-based content hashing
- Hit/miss statistics
- Automatic cleanup of stale entries

#### Tunnel Vision Prevention Status

| Category | Cases | Status |
|----------|-------|--------|
| Basic Static | localStorage, events, globals | ✅ 6/6 |
| Advanced | Workers, BroadcastChannel, WebSocket, SSE | ✅ 6/6 |
| CSS-in-JS | styled-components, emotion, theme-ui | ✅ 2/4 |
| TypeScript | interfaces, type dependencies | ✅ 2/4 |
| Redux/Context | selectors, actions, providers | ✅ 2/6 |
| **TOTAL** | **18/30** | **60%** |

**Next**: Finish remaining 12 cases (CSS-in-JS variants, TS generics, Context providers, etc.)