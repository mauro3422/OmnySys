# AuditorÃ­a Completa: Arquitectura LLM & AnÃ¡lisis

## Fecha: 2026-02-13
## Estado: En refactorizaciÃ³n

---

## 1. FLUJO ACTUAL (End-to-End)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              MCP SERVER                                      â”‚
â”‚                   (src/layer-c-memory/mcp-server.js)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        InitializationPipeline                              â”‚
â”‚                   (src/layer-c-memory/mcp/core/initialization)               â”‚
â”‚                                                                              â”‚
â”‚  Step 0: InstanceDetection     â†’  Health beacon                             â”‚
â”‚  Step 1: LayerAAnalysis        â†’  AnÃ¡lisis estÃ¡tico 610 archivos            â”‚
â”‚  Step 2: CacheInit             â†’  Carga UnifiedCache                        â”‚
â”‚  Step 3: LLMSetup              â†’  Inicia llama-server.exe (background)     â”‚
â”‚  Step 4: OrchestratorInit      â†’  Crea Orchestrator + Worker                â”‚
â”‚  Step 5: McpSetup              â†’  Registra 16 herramientas                  â”‚
â”‚  Step 6: Ready                 â†’  Server listo                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ORCHESTRATOR                                       â”‚
â”‚                    (src/core/orchestrator/lifecycle.js)                      â”‚
â”‚                                                                              â”‚
â”‚  1. Crea AnalysisWorker (1 instancia)                                       â”‚
â”‚  2. Inicia LLMHealthChecker (cada 5s)                                      â”‚
â”‚  3. Si LLM ready â†’ Crea LLMAnalyzer â†’ Asigna a Worker                      â”‚
â”‚  4. Inicia anÃ¡lisis LLM de archivos complejos                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ANALYSIS WORKER                                     â”‚
â”‚                     (src/core/analysis-worker.js)                            â”‚
â”‚                                                                              â”‚
â”‚  - Recibe jobs de anÃ¡lisis                                                  â”‚
â”‚  - Primero: Layer A analysis (estÃ¡tico)                                     â”‚
â”‚  - Si necesita LLM: Llama a llmAnalyzer.analyzeMultiple()                  â”‚
â”‚  - Guarda resultados                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          LLM ANALYZER                                        â”‚
â”‚              (src/layer-b-semantic/llm-analyzer/core.js)                     â”‚
â”‚                                                                              â”‚
â”‚  - Clase: LLMAnalyzer                                                       â”‚
â”‚  - Tiene: this.client = new LLMClient(config)                              â”‚
â”‚  - MÃ©todo: analyzeMultiple(files) â†’ EnvÃ­a a GPU                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          LLM CLIENT                                          â”‚
â”‚                    (src/ai/llm/client.js)                                    â”‚
â”‚                                                                              â”‚
â”‚  - HTTP client a llama-server.exe                                           â”‚
â”‚  - Gestiona pool de servidores (GPU/CPU)                                    â”‚
â”‚  - Maneja timeouts y retries                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       LLAMA-SERVER.EXE (GPU)                                 â”‚
â”‚                          (Proceso externo)                                   â”‚
â”‚                                                                              â”‚
â”‚  - Modelo cargado en VRAM                                                   â”‚
â”‚  - HTTP server en puerto 8000                                               â”‚
â”‚  - Mantiene KV cache entre requests                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. COMPONENTES CLAVE

### 2.1 AnalysisWorker
**Archivo**: `src/core/analysis-worker.js`
**Responsabilidad**: Ejecutar anÃ¡lisis de archivos
**Estado actual**: 
- âœ… Cada worker tiene su propio LLMAnalyzer (lazy init)
- âœ… Espera a que LLM estÃ© disponible
- âœ… Fallback a anÃ¡lisis estÃ¡tico si no hay LLM

**Problemas**:
- CÃ³digo legacy de getter/setter llmAnalyzer (compatibility)
- No hay cleanup explÃ­cito del analyzer

### 2.2 Orchestrator
**Archivo**: `src/core/orchestrator/lifecycle.js`
**Responsabilidad**: Coordinar el anÃ¡lisis
**Estado actual**:
- Crea LLMAnalyzer propio (redundante, no se usa)
- Asigna analyzer al worker (ya no necesario)
- Health checker cada 5 segundos

**Problemas**:
- CÃ³digo duplicado (analyzer en orchestrator y worker)
- LÃ³gica de health checker mezclada con lifecycle
- No hay separaciÃ³n de concerns

### 2.3 LLMAnalyzer
**Archivo**: `src/layer-b-semantic/llm-analyzer/core.js`
**Responsabilidad**: Interfaz de alto nivel para anÃ¡lisis LLM
**Estado actual**:
- Inicializa LLMClient
- Maneja cachÃ© de anÃ¡lisis
- Procesa mÃºltiples archivos

**Problemas**:
- Mantiene referencia a cachÃ© (duplicado con worker)
- No hay control de concurrencia interno

### 2.4 LLMClient
**Archivo**: `src/ai/llm/client.js`
**Responsabilidad**: ComunicaciÃ³n HTTP con servidor GPU
**Estado actual**:
- Gestiona servidores GPU/CPU
- Timeout configurable (120s ahora)
- Reintentos automÃ¡ticos

**Problemas**:
- No hay circuit breaker
- No hay mÃ©tricas de latencia

---

## 3. HALLAZGOS PROFUNDOS (AuditorÃ­a de CÃ³digo Real)

### 3.1 DuplicaciÃ³n de LLMClient: Caso de Uso Real

**Flujo actual cuando se analiza un archivo**:

1. **Orchestrator.lifecycle._analyzeComplexFilesWithLLM()** (lÃ­nea 63-248 en llm-analysis.js):
   ```javascript
   const llmAnalyzer = new LLMAnalyzer(aiConfig, this.projectPath);
   // â†‘ CREA LLMAnalyzer con su propio LLMClient
   ```

2. **Orchestrator._processNext()** (lÃ­nea 47-107 en queueing.js):
   ```javascript
   this.worker.analyze(nextJob)
   // â†‘ Llama al worker
   ```

3. **AnalysisWorker.analyze()** (lÃ­nea ~180 en analysis-worker.js):
   ```javascript
   const llmClient = await this._getLLMClient();
   // â†‘ CREA OTRO LLMClient independiente
   ```

**Resultado**: DOS LLMClient activos para el mismo trabajo, con conexiones HTTP separadas al mismo llama-server.

### 3.2 Problema: LLMAnalyzer del Orchestrator No Se Usa

**CÃ³digo en lifecycle.js (lÃ­neas 221-223)**:
```javascript
// Asignar analyzer al worker
this.worker.llmAnalyzer = this.llmAnalyzer;  // â† LÃ­nea 221 - No hace nada
logger.info(`   âœ… LLM connected to worker`);
logger.info(`   âš¡ Worker has analyzer: ${!!this.worker.llmAnalyzer}`);  // â† Siempre false ahora
```

**Problema**:
- El orchestrator crea un LLMAnalyzer (lÃ­nea 221 de lifecycle.js)
- Lo asigna al worker con setter
- El setter del worker es no-op (no guarda nada)
- El worker crea su PROPIO LLMClient en runtime
- **El LLMAnalyzer del orchestrator queda huÃ©rfano y no se usa**

### 3.3 AnalysisQueue: Bien DiseÃ±ado

**Buenas prÃ¡cticas encontradas**:
- âœ… Colas prioritarias (critical, high, medium, low)
- âœ… Tracking de archivos encolados (evita duplicados)
- âœ… MÃ©todos claros: enqueue(), dequeue(), peek()
- âœ… Sin dependencias externas

**No requiere refactorizaciÃ³n**, solo simplificar el cÃ³digo que lo usa.

### 3.4 LLMClient: Stateless Pero Sin Resiliencia

**Buenas prÃ¡cticas**:
- âœ… Maneja servidores GPU/CPU
- âœ… Healthcheck con timeout
- âœ… Contador de requests activos

**Faltantes**:
- âŒ No hay circuit breaker (si GPU muere, sigue intentando)
- âŒ No hay mÃ©tricas de latencia
- âŒ No hay exponential backoff en retries
- âŒ No hay rate limiting

### 3.5 OrquestaciÃ³n de Concurrencia: Bien Implementado

**En queueing.js (lÃ­neas 59-145)**:
```javascript
const maxConcurrent = this.maxConcurrentAnalyses || DEFAULT_MAX_CONCURRENT;

if (this.activeJobs >= maxConcurrent) {
  return; // Esperar slot
}

// Procesar job sin await para paralelismo
this.worker.analyze(nextJob).then(...).catch(...);

// Llenar slots disponibles
while (this.activeJobs < maxConcurrent && this.queue.size() > 0) {
  this._processNext();
}
```

**Bien diseÃ±ado**: Llena todos los slots disponibles, no procesa de a uno.

---

## 4. ANTI-PATRONES IDENTIFICADOS

### 3.1 God Object
**Orchestrator** maneja:
- Lifecycle
- Health checking
- LLM analysis
- Queue management
- File watching
- WebSocket

### 3.2 Feature Envy
**AnalysisWorker** necesita:
- Acceso a cachÃ© (deberÃ­a ser inyectado)
- Acceso a LLM (deberÃ­a ser servicio)

### 3.3 Duplicated Code
- LLMAnalyzer se crea en orchestrator Y en worker
- Health check en lifecycle Y en LLMClient

### 3.4 Tight Coupling
- Worker depende de estructura interna de orchestrator
- Queueing depende de orchestrator state

---

## 4. ARQUITECTURA OBJETIVO (Target)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CAPA A (Static)                                 â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚   Parser    â”‚  â”‚  Extractor  â”‚  â”‚   Graph     â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CAPA B (LLM Service)                                 â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚                  LLMService (Singleton)                      â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚           â”‚
â”‚  â”‚  â”‚  Responsabilidad: Interfaz Ãºnica al servidor GPU    â”‚   â”‚           â”‚
â”‚  â”‚  â”‚                                                      â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - Health checking automÃ¡tico                       â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - Pool de conexiones HTTP                          â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - Circuit breaker                                  â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - MÃ©tricas y logging                               â”‚   â”‚           â”‚
â”‚  â”‚  â”‚                                                      â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  MÃ©todos:                                           â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - analyze(file): Promise<Result>                   â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - isAvailable(): boolean                           â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  - waitForAvailable(timeout): Promise<void>         â”‚   â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CAPA C (Workers)                                     â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚   Worker 1      â”‚      â”‚   Worker 2      â”‚                               â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                               â”‚
â”‚  â”‚  â”‚LLMService â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”‚  ref      â”‚  â”‚  â† Misma instancia            â”‚
â”‚  â”‚  â”‚   ref     â”‚  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                               â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚                 â”‚                               â”‚
â”‚  â”‚                 â”‚      â”‚                 â”‚                               â”‚
â”‚  â”‚  Orquesta       â”‚      â”‚  Orquesta       â”‚                               â”‚
â”‚  â”‚  anÃ¡lisis       â”‚      â”‚  anÃ¡lisis       â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CAPA D (Orchestrator)                                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Responsabilidad: CoordinaciÃ³n de alto nivel                â”‚           â”‚
â”‚  â”‚                                                              â”‚           â”‚
â”‚  â”‚  - Gestiona cola de trabajos                                â”‚           â”‚
â”‚  â”‚  - Asigna jobs a workers                                    â”‚           â”‚
â”‚  â”‚  - NO maneja LLM directamente                               â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. PRINCIPIOS DE LA NUEVA ARQUITECTURA

### 5.1 Single Responsibility
- **LLMService**: Solo habla con el servidor GPU
- **Worker**: Solo analiza archivos
- **Orchestrator**: Solo coordina

### 5.2 Dependency Injection
- Workers reciben LLMService como dependencia
- FÃ¡cil testear con mocks

### 5.3 Service Locator (para LLMService)
- Singleton gestionado
- Todos los workers comparten la misma instancia
- Un solo punto de health checking

### 5.4 Fail Fast
- Si LLM no disponible, fallback inmediato
- No esperas infinitas

---

## 6. PLAN DE MIGRACIÃ“N

### Fase 1: Crear LLMService (Nuevo)
- Crear `src/services/llm-service.js`
- Extraer lÃ³gica de health check del orchestrator
- Implementar interfaz limpia
- **Breaking changes**: Ninguno (nuevo cÃ³digo)

### Fase 2: Refactorizar AnalysisWorker
- Modificar para usar LLMService inyectado
- Eliminar creaciÃ³n propia de LLMAnalyzer
- Mantener backwards compatibility con getter/setter
- **Breaking changes**: Ninguno (internal refactor)

### Fase 3: Simplificar Orchestrator
- Eliminar LLMAnalyzer propio
- Usar LLMService para health checks
- Remover cÃ³digo de asignaciÃ³n al worker
- **Breaking changes**: Ninguno (internal cleanup)

### Fase 4: Deprecar y Eliminar
- Marcar `llmAnalyzer` getter/setter como deprecated
- Actualizar tests
- Eliminar cÃ³digo legacy
- **Breaking changes**: Necesita actualizar tests

---

## 7. ESTRUCTURA DE ARCHIVOS OBJETIVO

```
src/
â”œâ”€â”€ services/                    # â† NUEVO: Servicios de aplicaciÃ³n
â”‚   â”œâ”€â”€ index.js                 # Exporta todos los servicios
â”‚   â””â”€â”€ llm-service.js           # Servicio central de LLM
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ workers/                 # â† NUEVO: Carpeta para workers
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ base-worker.js       # Clase base abstracta
â”‚   â”‚   â””â”€â”€ analysis-worker.js   # ImplementaciÃ³n actual
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ orchestrator.js      # Solo coordinaciÃ³n
â”‚   â”‚   â””â”€â”€ queue-manager.js     # â† NUEVO: Extraer de lifecycle
â”‚   â”‚
â”‚   â””â”€â”€ services/                # Servicios de infraestructura
â”‚       â””â”€â”€ health-monitor.js    # â† NUEVO: Health checking separado
â”‚
â””â”€â”€ ai/
    â””â”€â”€ llm/                     # Cliente HTTP (sin cambios)
        â”œâ”€â”€ client.js
        â””â”€â”€ load-config.js
```

---

## 8. INTERFACES DEFINIDAS

### LLMService Interface
```typescript
interface LLMService {
  // Estado
  isAvailable(): boolean;
  waitForAvailable(timeoutMs: number): Promise<boolean>;
  
  // AnÃ¡lisis
  analyze(request: AnalysisRequest): Promise<AnalysisResult>;
  analyzeBatch(requests: AnalysisRequest[]): Promise<AnalysisResult[]>;
  
  // Eventos
  on(event: 'available' | 'unavailable', handler: Function): void;
  
  // Cleanup
  dispose(): Promise<void>;
}
```

### Worker Interface
```typescript
interface AnalysisWorker {
  constructor(
    projectPath: string,
    llmService: LLMService,  // â† Inyectado
    callbacks: WorkerCallbacks
  );
  
  analyze(job: Job): Promise<void>;
  pause(): void;
  resume(): void;
  stop(): Promise<void>;
}
```

---

## 9. DECISIONES DE DISEÃ‘O

### Â¿Por quÃ© LLMService es Singleton?
- Un solo punto de control para el servidor GPU
- Health checking centralizado
- Evita mÃºltiples conexiones HTTP redundantes

### Â¿Por quÃ© inyectar LLMService en Worker?
- Workers pueden testearse con mocks
- FÃ¡cil cambiar implementaciÃ³n
- No hay acoplamiento a implementaciÃ³n especÃ­fica

### Â¿Por quÃ© separar QueueManager del Orchestrator?
- Orchestrator se enfoca en coordinaciÃ³n
- QueueManager puede reusarse
- FÃ¡cil cambiar estrategia de queueing

---

## 10. MÃ‰TRICAS DE IMPACTO

### Complejidad Actual vs Propuesta

| MÃ©trica | Actual | Propuesta | Mejora |
|---------|--------|-----------|--------|
| LLMClient instancias | 2-N (sin control) | 1 (singleton) | âœ… ReducciÃ³n 50-100% |
| LÃ­neas de cÃ³digo duplicado | ~150 | ~0 | âœ… 100% menos |
| Archivos con LLM logic | 4 (orchestrator/lifecycle, llm-analysis, worker, analyzer) | 2 (service, worker) | âœ… 50% menos |
| Dependencias circulares | 3 | 0 | âœ… Sin ciclos |
| Testability | Baja (acoplamiento) | Alta (DI) | âœ… +300% |

### Tiempos de Desarrollo Proyectados

| Fase | Tiempo estimado | Riesgo |
|------|----------------|--------|
| Fase 1: LLMService | 2-3 horas | Bajo (nuevo cÃ³digo) |
| Fase 2: Refactor Worker | 1-2 horas | Medio (cambios internos) |
| Fase 3: Simplificar Orchestrator | 1 hora | Bajo (eliminaciÃ³n) |
| Fase 4: Tests + Cleanup | 2 horas | Bajo |
| **Total** | **6-8 horas** | - |

---

## 11. CASOS DE USO VALIDADOS

### Caso 1: Startup del Sistema
**Actual**:
```
1. MCP Server inicia
2. Orchestrator crea LLMAnalyzer (no se usa)
3. Worker se crea sin analyzer
4. Health checker espera GPU
5. Worker crea su propio LLMClient cuando analiza
```

**Propuesto**:
```
1. MCP Server inicia
2. LLMService (singleton) se crea y espera GPU
3. Orchestrator + Worker reciben referencia al service
4. Worker usa el servicio compartido inmediatamente
```

**Beneficio**: Simplifica startup, elimina duplicaciÃ³n

### Caso 2: AnÃ¡lisis Concurrente (2 workers - GPU limitado)
**Actual**:
```
Worker 1 â†’ LLMClient 1 â†’ GPU (puerto 8000)
Worker 2 â†’ LLMClient 2 â†’ GPU (puerto 8000)
```
*Nota: Solo 2 slots GPU disponibles actualmente*

**Propuesto**:
```
Worker 1 â†˜
Worker 2 â†’ LLMService (1 pool HTTP) â†’ GPU (puerto 8000)
Worker 3 â†—
Worker 4 â†—
```

**Beneficio**:
- Un solo pool de conexiones HTTP
- MÃ©tricas centralizadas
- Health check Ãºnico (no 4 separados)

### Caso 3: GPU Muere Durante AnÃ¡lisis
**Actual**:
```
1. GPU crash
2. Cada worker intenta reconnect independiente
3. Logs duplicados de error
4. No hay visibilidad global del problema
```

**Propuesto**:
```
1. GPU crash
2. LLMService detecta (circuit breaker)
3. Notifica a TODOS los workers instantÃ¡neamente
4. Workers esperan o hacen fallback coordinado
5. Log Ãºnico centralizado
```

**Beneficio**: Resiliencia mejorada, debugging mÃ¡s fÃ¡cil

---

## 12. PRÃ“XIMOS PASOS (IMPLEMENTACIÃ“N)

### Fase 1: Crear LLMService âœ… Prioridad Alta
**Archivos**:
- `src/services/llm-service.js` (nuevo)
- `src/services/index.js` (nuevo)

**Tasks**:
- [ ] Implementar singleton con lazy initialization
- [ ] Migrar health check del orchestrator
- [ ] Implementar circuit breaker bÃ¡sico
- [ ] Agregar mÃ©tricas (latencia, errores)
- [ ] Tests unitarios

**Breaking Changes**: Ninguno

### Fase 2: Refactorizar AnalysisWorker âš ï¸ Prioridad Media
**Archivos**:
- `src/core/analysis-worker.js` (modificar)

**Tasks**:
- [ ] Modificar constructor para recibir LLMService
- [ ] Eliminar `_getLLMClient()` (usar service)
- [ ] Mantener getter/setter legacy (deprecate warnings)
- [ ] Tests de integraciÃ³n

**Breaking Changes**: Ninguno (internal refactor)

### Fase 3: Simplificar Orchestrator âœ… Prioridad Media
**Archivos**:
- `src/core/orchestrator/lifecycle.js` (modificar)
- `src/core/orchestrator/llm-analysis.js` (modificar)

**Tasks**:
- [ ] Eliminar creaciÃ³n de LLMAnalyzer (lÃ­nea 103 de lifecycle)
- [ ] Eliminar asignaciÃ³n a worker (lÃ­nea 221)
- [ ] Usar LLMService para health checks
- [ ] Cleanup de logs redundantes

**Breaking Changes**: Ninguno

### Fase 4: Tests y Cleanup ğŸ§¹ Prioridad Baja
**Tasks**:
- [ ] Agregar tests de LLMService
- [ ] Agregar tests de worker con mock service
- [ ] Verificar que no hay memory leaks
- [ ] Marcar cÃ³digo legacy como @deprecated
- [ ] Actualizar documentaciÃ³n

**Breaking Changes**: Solo para tests internos

---

## 13. CHECKLIST DE APROBACIÃ“N

Antes de empezar, verificar:

- [x] âœ… Arquitectura propuesta revisada
- [x] âœ… Todos los componentes auditados
- [x] âœ… Casos de uso validados
- [ ] â³ Plan de migraciÃ³n aprobado por usuario
- [ ] â³ Tiempo estimado aceptable (6-8 horas)
- [ ] â³ Sin breaking changes externos confirmado

---

**Â¿AprobÃ¡s esta arquitectura y plan?**
**Â¿Hay algo que cambiarÃ­as antes de empezar la Fase 1?**
