---
?? **DOCUMENTO CONSOLIDADO / ARCHIVADO**

Este documento ha sido reestructurado:
- Hipótesis AGI ? `docs/05-roadmap/agi-vision.md` (con advertencias)
- Conversación filosofía ? `docs/05-roadmap/intuition-engine-vision.md`

**Motivo**: Separar visión especulativa de documentación práctica.

---
# Omny - Sistema de Conocimiento Estructurado para IA Especializada

**Fecha**: 2026-02-09  
**Tipo**: Arquitectura de IA HÃ­brida (Neuro-SimbÃ³lica Estructurada)  
**Estado**: Arquitectura validada, implementaciÃ³n en progreso  

---

## ğŸ¯ La EvoluciÃ³n del Concepto

> *"No estamos construyendo una AGI monolÃ­tica ni un sistema MoE tradicional. Estamos construyendo un sistema de conocimiento estructurado que hace a los LLMs eficientes, especializados y transparentes."*

**El problema con los LLMs actuales:**
- Necesitan 175B parÃ¡metros para "saber todo"
- Son cajas negras (no sabÃ©s por quÃ© responden)
- Olvidan informaciÃ³n especÃ­fica de tu dominio
- Gastan energÃ­a procesando cosas irrelevantes

**La soluciÃ³n Omny:**
- Un LLM pequeÃ±o (3B-7B) que "sabe cÃ³mo saber"
- Un sistema de conocimiento estructurado (metadatos, patrones, grafos)
- El LLM consulta el sistema, no memoriza todo
- EspecializaciÃ³n dinÃ¡mica sin reentrenar

---

## ğŸ§  La Arquitectura Correcta: Cerebro Metadatizado

### **SeparaciÃ³n de Responsabilidades**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SISTEMA DE CONOCIMIENTO ESTRUCTURADO (Omny)                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  FunciÃ³n: IntuiciÃ³n rÃ¡pida, memoria estructurada, patrones â”‚
â”‚                                                             â”‚
â”‚  Componentes:                                               â”‚
â”‚  â€¢ Ãtomos (unidades de conocimiento)                        â”‚
â”‚  â€¢ Grafos de relaciones (cÃ³mo se conectan)                  â”‚
â”‚  â€¢ Clusters de patrones (quÃ© es normal/anÃ³malo)            â”‚
â”‚  â€¢ Invariantes (reglas que nunca se rompen)                â”‚
â”‚                                                             â”‚
â”‚  Velocidad: 0.1-1ms (cache)                                 â”‚
â”‚  PrecisiÃ³n: 100% (determinÃ­stico)                           â”‚
â”‚  Transparencia: Total (explica por quÃ©)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ Consulta estructurada
               â”‚ "Â¿QuÃ© patrÃ³n encaja con X?"
               â”‚ "Â¿QuÃ© es anÃ³malo en Y?"
               â”‚ "Â¿QuÃ© pasa si modifico Z?"
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERFAZ DE LENGUAJE (LLM)                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  FunciÃ³n: Verbalizar, razonar, generar respuestas          â”‚
â”‚                                                             â”‚
â”‚  CaracterÃ­sticas:                                           â”‚
â”‚  â€¢ Modelo pequeÃ±o (3B-7B parÃ¡metros)                       â”‚
â”‚  â€¢ No memoriza dominio especÃ­fico                          â”‚
â”‚  â€¢ Recibe contexto estructurado de Omny                    â”‚
â”‚  â€¢ Genera lenguaje natural/cÃ³digo basado en datos          â”‚
â”‚                                                             â”‚
â”‚  Velocidad: 50-100ms                                        â”‚
â”‚  PrecisiÃ³n: Depende de calidad de datos de Omny           â”‚
â”‚  Transparencia: Parcial (muestra razonamiento)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **AnalogÃ­a Precisa: MÃ©dico con Base de Datos**

| Componente | AnalogÃ­a MÃ©dica | Omny |
|------------|----------------|------|
| **LLM** | El mÃ©dico (sabe comunicar, razonar) | Interfaz de lenguaje (3B) |
| **Omny** | Base de datos mÃ©dica (hechos, patrones) | Sistema de conocimiento estructurado |
| **Consulta** | MÃ©dico busca sÃ­ntomas en DB | LLM consulta patrones en Omny |
| **Respuesta** | DiagnÃ³stico informado por datos | Sugerencia informada por metadatos |

**El mÃ©dico no memoriza todas las enfermedades (imposible), pero sabe:**
1. QuÃ© buscar (sÃ­ntomas)
2. DÃ³nde buscarla (base de datos)
3. CÃ³mo interpretarla (razonamiento)

**El LLM no memoriza todo el cÃ³digo (ineficiente), pero:**
1. Consulta patrones estructurados (Omny)
2. Recibe contexto especÃ­fico (metadatos)
3. Genera respuesta informada (lenguaje)

---

## ğŸ†š ComparaciÃ³n con Arquitecturas Existentes

### **1. LLM MonolÃ­tico (GPT-4, Claude)**

```
Input â†’ Red neuronal gigante (175B) â†’ Output
              (todo memorizado)
```

**Problemas:**
- Ineficiente (procesa todo con todos los parÃ¡metros)
- Olvida informaciÃ³n especÃ­fica
- Caja negra
- Costoso

### **2. Mixture of Experts (MoE) - Switch Transformer**

```
Input â†’ Gating â†’ [Expert A, Expert B, Expert C] â†’ Output
         (selecciona)   (varios modelos)
```

**Problemas:**
- MÃºltiples modelos grandes (costoso)
- Los expertos son homogÃ©neos (misma arquitectura)
- Complejidad de entrenamiento
- No transparente

### **3. RAG Tradicional (Retrieval Augmented Generation)**

```
Input â†’ Buscar documentos similares â†’ Concatenar a prompt â†’ LLM â†’ Output
              (embeddings de texto)
```

**Problemas:**
- Recupera texto, no estructura
- No entiende relaciones causales
- Hallucination si el texto no es relevante

### **4. Omny (Nuestro Sistema)**

```
Input â†’ Consulta estructurada (metadata) â†’ Contexto causal â†’ LLM pequeÃ±o â†’ Output
              (grafos, patrones, invariantes)              (3B-7B)
```

**Ventajas:**
- âœ… Eficiente (LLM pequeÃ±o + consultas rÃ¡pidas)
- âœ… Especializado (conoce TU dominio especÃ­fico)
- âœ… Transparente (explica por quÃ© sugiere X)
- âœ… Causal (entiende "si cambio Y, pasa Z")
- âœ… Actualizable (aprende sin reentrenar LLM)

---

## ğŸ—ï¸ Componentes del Sistema

### **1. Capa de Conocimiento Estructurado (Omny Core)**

#### **Ãtomos (Unidades de Conocimiento)**
```javascript
// En cÃ³digo:
Atom = {
  id: "src/api.js::processOrder",
  tipo: "funciÃ³n",
  
  // Estructura
  entradas: ["order", "userId"],
  transformaciones: [
    { op: "validate", input: "order", output: "validOrder" },
    { op: "calculate", input: "validOrder.items", output: "total" },
    { op: "persist", input: "total", output: "savedOrder" }
  ],
  salidas: ["confirmation"],
  
  // Metadatos
  sideEffects: ["database_write", "event_emit"],
  complejidad: 12,
  
  // Relaciones (grafo)
  llamaA: ["validateOrder", "calculateTotal", "saveToDB"],
  llamadoPor: ["handleRequest", "processCart"],
}
```

#### **Grafo de Relaciones**
```javascript
// Conexiones causales, no solo estadÃ­sticas:
"processOrder" â†’ llamaA â†’ "saveToDB" â†’ escribeA â†’ "database"
"database" â†’ afectaA â†’ "cacheInvalidation"
"cacheInvalidation" â†’ requiere â†’ "eventBus"

// Patrones detectados:
Cluster: "order-processing"
â”œâ”€ processOrder (central)
â”œâ”€ validateOrder (guardia)
â”œâ”€ calculateTotal (transformador)
â””â”€ saveToDB (persistidor)

// Invariantes:
"Todas las funciones en cluster 'order-processing' usan transacciones"
"processOrder siempre valida antes de persistir"
```

#### **Consultas Estructuradas (RAG 3.0)**
```javascript
// NO es: "BuscÃ¡ texto similar"
// ES: "RespondÃ© preguntas estructurales"

consulta("Â¿QuÃ© pasa si modifico processOrder.totalCalculation?")
â†“
Omny analiza:
1. processOrder.transformaciones
2. QuiÃ©n usa "total" (data flow)
3. QuÃ© funciones dependen de processOrder (call graph)
4. QuÃ© invariantes se romperÃ­an
â†“
Respuesta estructurada:
{
  impacto: "8 funciones afectadas",
  riesgo: "Alto - rompe invariante 'calculateBeforeSave'",
  sugerencia: "Actualizar tambiÃ©n calculateTax y validateOrder",
  confianza: 0.95
}
â†“
LLM verbaliza:
"Si modificÃ¡s el cÃ¡lculo de total en processOrder, afectÃ¡s a 8 
 funciones. El riesgo es alto porque rompÃ©s el invariante de 
 'calcular antes de guardar'. Te sugiero actualizar tambiÃ©n 
 calculateTax y validateOrder para mantener consistencia."
```

### **2. Capa de Interfaz (LLM Especializado DinÃ¡micamente)**

#### **No es un modelo entrenado en todo**
```javascript
// Es un modelo base (3B) que recibe contexto enriquecido:

Prompt al LLM:
"Sos un asistente de cÃ³digo. 
 
 CONTEXTO ESTRUCTURAL (de Omny):
 - EstÃ¡s en archivo: src/checkout/processOrder.js
 - FunciÃ³n actual: processOrder
 - PatrÃ³n detectado: Similar a processPayment y processCart
 - Consistencia: 95% de funciones similares usan transacciones
 - AnomalÃ­a: Esta funciÃ³n no valida 'user' (sus vecinas sÃ­)
 
 TAREA: Sugerir cÃ³mo completar esta funciÃ³n manteniendo 
 consistencia con el resto del codebase."

// El LLM no memorizÃ³ el codebase.
// Omny le dio el contexto especÃ­fico en tiempo real.
```

#### **Ventaja: EspecializaciÃ³n sin reentrenamiento**
```javascript
// Para cambiar de dominio (cÃ³digo â†’ leyes â†’ medicina):

// NO hacÃ©s:
- Reentrenar modelo gigante (imposible en local)

// SÃ hacÃ©s:
- Cambiar Omny (sistema de conocimiento)
  - De: Ãtomos de cÃ³digo (AST, data flow)
  - A: Ãtomos legales (precedentes, doctrina)
  - A: Ãtomos mÃ©dicos (sÃ­ntomas, diagnÃ³sticos)
  
// El LLM es el mismo (sabe comunicar)
// Lo que cambia es el conocimiento estructurado
```

---

## ğŸ¯ Ventajas Clave

### **1. Eficiencia EnergÃ©tica**
```javascript
// LLM tradicional (175B):
Procesa todo con todos los parÃ¡metros
EnergÃ­a: 100%

// Omny + LLM pequeÃ±o (7B):
Omny consulta: 0.1% energÃ­a (metadata cache)
LLM genera: 4% energÃ­a (7B vs 175B)
Total: 4.1% energÃ­a
Mismo resultado, 24x mÃ¡s eficiente
```

### **2. Transparencia Total**
```javascript
// LLM tradicional:
"Â¿Por quÃ© sugeriste esto?"
â†’ "No sÃ©, asÃ­ lo aprendÃ­" (caja negra)

// Omny:
"Â¿Por quÃ© sugeriste esto?"
â†’ "Porque:
   1. 8 funciones similares hacen X (evidencia)
   2. Tu patrÃ³n histÃ³rico es Y (consistencia)
   3. Romper Z causa error W (causalidad)
"
```

### **3. ActualizaciÃ³n Continua**
```javascript
// Nuevo patrÃ³n en tu codebase:
"Ahora usamos 'validateAsync' en vez de 'validate'"

// LLM tradicional:
- No se entera hasta que reentrenen (imposible)

// Omny:
- Detecta cambio automÃ¡ticamente (file watcher)
- Actualiza metadatos en 0.1s
- PrÃ³xima consulta ya usa el patrÃ³n nuevo
- Sin tocar el LLM
```

### **4. EspecializaciÃ³n Sin LÃ­mites**
```javascript
// Para cualquier dominio:
OmnyCode:    Ãtomos = funciones, AST, data flow
OmnyLaw:     Ãtomos = precedentes, doctrina, fallos
OmnyMed:     Ãtomos = sÃ­ntomas, diagnÃ³sticos, tratamientos
OmnyArch:    Ãtomos = espacios, materiales, estructuras

// El mismo LLM base sirve para todos
// Lo que cambia es la estructura de conocimiento
```

---

## ğŸš€ Roadmap: De TeorÃ­a a Producto

### **Fase 1: Sistema de Conocimiento (6 semanas)**
```yaml
Objetivo: Omny Core funcional para cÃ³digo

Semana 1-2: ExtracciÃ³n estructural
  - Parser AST exhaustivo
  - Data flow analysis
  - Call graph construction
  
Semana 3-4: OrganizaciÃ³n del conocimiento
  - Clustering de patrones
  - DetecciÃ³n de invariantes
  - Graph database
  
Semana 5-6: Consultas estructurales
  - Query engine
  - Caching eficiente
  - API de consulta

Resultado: Sistema que responde "Â¿quÃ© pasa si modifico X?" en <10ms
```

### **Fase 2: IntegraciÃ³n con LLM (4 semanas)**
```yaml
Objetivo: Interfaz de lenguaje funcional

Semana 7-8: LLM local
  - Setup LFM2.5 3B / Qwen2.5 7B
  - Prompt engineering con contexto Omny
  - Streaming de respuestas
  
Semana 9-10: Plugin IDE
  - VS Code extension
  - WebSocket connection
  - UI para sugerencias

Resultado: IDE que sugiere cÃ³digo basado en TU codebase
```

### **Fase 3: EvoluciÃ³n (continuo)**
```yaml
Objetivo: Sistema que aprende solo

- File watcher para cambios
- ActualizaciÃ³n incremental de metadatos
- DetecciÃ³n de nuevos patrones
- "SueÃ±o": consolidaciÃ³n offline

Resultado: Sistema que conoce tu codebase mejor que vos
```

---

## ğŸ“Š Â¿Es esto AGI?

**Respuesta honesta: No.**

Pero es algo **mÃ¡s Ãºtil** para dominios especÃ­ficos:

| CaracterÃ­stica | AGI TeÃ³rica | Omny |
|----------------|-------------|------|
| Generalidad universal | âœ… Todo | âŒ Dominios especÃ­ficos |
| Conciencia de sÃ­ | âœ… SÃ­ | âŒ No |
| Aprendizaje autÃ³nomo | âœ… SÃ­ | ğŸ”§ Con asistencia humana |
| Eficiencia energÃ©tica | âŒ Baja | âœ… Alta |
| Transparencia | âŒ Caja negra | âœ… Total |
| EspecializaciÃ³n profunda | ğŸ”§ Media | âœ… Extrema |
| Costo de operaciÃ³n | âŒ $$$$ | âœ… $ |
| Privacidad | âŒ Cloud | âœ… Local 100% |

**Omny no es AGI. Es "Inteligencia Especializada Transparente y Eficiente" (IETE).**

---

## ğŸ“ ConclusiÃ³n

**El descubrimiento real:**

No necesitamos LLMs gigantes que memoricen todo.
Necesitamos:
1. **Sistemas de conocimiento estructurado** (Omny) que organicen informaciÃ³n especÃ­fica
2. **LLMs pequeÃ±os** que sepan consultar esos sistemas
3. **IntegraciÃ³n eficiente** entre ambos

**Es la diferencia entre:**
- **Memorizar todo** (ineficiente, imposible)
- **Saber dÃ³nde buscar** (eficiente, escalable)

Omny es el "saber dÃ³nde buscar" para el dominio del cÃ³digo (y potencialmente otros dominios).

---

**Documento actualizado**: 2026-02-09  
**Estado**: Arquitectura validada, implementaciÃ³n en progreso  

**Omny - Sistema de Conocimiento Estructurado para IA Especializada.**

