# An√°lisis de Edge Cases - Arquitectura LLMService

## Fecha: 2026-02-14
## Estado: ‚úÖ Validado

---

## 1. FLUJO DE DATOS END-TO-END

### Secuencia Normal de Inicializaci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. MCP Server Inicia                                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    ‚Üì                                                            ‚îÇ
‚îÇ 2. Initialization Pipeline                                      ‚îÇ
‚îÇ    - Step 0: InstanceDetection                                  ‚îÇ
‚îÇ    - Step 1: LayerAAnalysis (610 archivos)                      ‚îÇ
‚îÇ    - Step 2: CacheInit                                          ‚îÇ
‚îÇ    - Step 3: LLMSetup (background)                              ‚îÇ
‚îÇ    - Step 4: OrchestratorInit ‚Üê LLMService.getInstance()        ‚îÇ
‚îÇ    - Step 5: McpSetup                                           ‚îÇ
‚îÇ    - Step 6: Ready                                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    ‚Üì                                                            ‚îÇ
‚îÇ 3. Orchestrator.initialize()                                    ‚îÇ
‚îÇ    - Crea cache                                                 ‚îÇ
‚îÇ    - Crea state manager                                         ‚îÇ
‚îÇ    - LLMService.getInstance() ‚Üê Singleton creado/acceso         ‚îÇ
‚îÇ    - new AnalysisWorker(rootPath, callbacks)                    ‚îÇ
‚îÇ    - worker.initialize() ‚Üê Obtiene LLMService                   ‚îÇ
‚îÇ    - _startLLMHealthChecker() ‚Üê Monitorea LLMService            ‚îÇ
‚îÇ    - _analyzeComplexFilesWithLLM() ‚Üê Usa LLMService             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    ‚Üì                                                            ‚îÇ
‚îÇ 4. Analysis Worker                                              ‚îÇ
‚îÇ    - _getLLMService() ‚Üê Obtiene singleton                       ‚îÇ
‚îÇ    - analyze(job)                                               ‚îÇ
‚îÇ      ‚îú‚îÄ Layer A analysis (est√°tico)                             ‚îÇ
‚îÇ      ‚îú‚îÄ if needsLLM: _getLLMService()                           ‚îÇ
‚îÇ      ‚îÇ   ‚îú‚îÄ if available: LLM analysis                          ‚îÇ
‚îÇ      ‚îÇ   ‚îî‚îÄ if not available: Fallback est√°tico                 ‚îÇ
‚îÇ      ‚îî‚îÄ Guarda resultados                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. EDGE CASES ANALIZADOS

### Caso 1: GPU No Disponible al Inicio

**Escenario**: llama-server.exe no est√° corriendo cuando inicia el sistema

**Comportamiento**:
```
1. LLMService.initialize() ‚Üí Crea cliente, health check falla
2. LLMService._available = false
3. Worker se crea, llama a LLMService.getInstance() ‚Üí Obtiene instancia
4. Worker._getLLMService() ‚Üí waitForAvailable(5000) ‚Üí false
5. Worker hace fallback a an√°lisis est√°tico
6. Health checker contin√∫a intentando cada 5s
7. Cuando GPU est√© disponible ‚Üí Worker usa LLM autom√°ticamente
```

**Resultado**: ‚úÖ Sistema funciona con an√°lisis est√°tico, transici√≥n autom√°tica a LLM

---

### Caso 2: GPU Muere Durante An√°lisis

**Escenario**: GPU server se cae mientras se analiza un archivo

**Comportamiento**:
```
1. Worker tiene referencia a LLMService
2. Worker llama a llmService.client.analyze()
3. fetch() falla (connection refused/timeout)
4. LLMService.catch(error):
   - Incrementa _cbFailureCount
   - Si >= 5: Circuit breaker ‚Üí OPEN
   - Emite evento 'error'
5. Worker recibe error, hace fallback
6. Pr√≥ximas llamadas fallan inmediatamente (CB OPEN)
7. Despu√©s de 30s: CB ‚Üí HALF_OPEN (prueba recuperaci√≥n)
8. Si √©xito: CB ‚Üí CLOSED
```

**Resultado**: ‚úÖ Circuit breaker protege el sistema, no hay cascada de fallos

---

### Caso 3: M√∫ltiples Workers Concurrentes (2 slots GPU)

**Escenario**: 2 workers analizando simult√°neamente

**Comportamiento**:
```
Worker 1 ‚îÄ‚îÄ‚îê
           ‚îú‚îÄ‚îÄ‚Üí LLMService (1 instancia)
Worker 2 ‚îÄ‚îÄ‚îò    ‚îú‚îÄ‚îÄ‚Üí LLMClient (1 instancia)
                ‚îÇ       ‚îú‚îÄ‚îÄ‚Üí GPU Server (2 slots)
                ‚îÇ       ‚îî‚îÄ‚îÄ‚Üí HTTP connections (pool)
                ‚îî‚îÄ‚îÄ‚Üí Circuit breaker (estado compartido)

Ambos workers comparten:
- Mismo LLMClient (mismo pool de conexiones)
- Mismo circuit breaker
- Mismas m√©tricas
- Mismo health checking
```

**Resultado**: ‚úÖ Un solo punto de control, m√©tricas centralizadas, eficiente

---

### Caso 4: Race Condition en Inicializaci√≥n

**Escenario**: Dos componentes piden LLMService simult√°neamente

**Comportamiento**:
```
Componente A ‚îÄ‚îÄ‚îê
               ‚îú‚îÄ‚îÄ‚Üí LLMService.getInstance()
Componente B ‚îÄ‚îÄ‚îò    ‚îú‚îÄ‚îÄ‚Üí _instancePromise (primero en llegar)
                    ‚îÇ       ‚îú‚îÄ‚îÄ‚Üí new LLMService()
                    ‚îÇ       ‚îú‚îÄ‚îÄ‚Üí initialize()
                    ‚îÇ       ‚îî‚îÄ‚îÄ‚Üí _instance = this
                    ‚îî‚îÄ‚îÄ‚Üí Ambos reciben misma instancia

_Singleton pattern con promise previene duplicaci√≥n_
```

**Resultado**: ‚úÖ Promise guard previene m√∫ltiples instancias

---

### Caso 5: Memory Leak en Health Checking

**Escenario**: Health checker corre por horas/d√≠as

**Comportamiento**:
```
setInterval cada 5s ‚Üí 12 checks/minuto ‚Üí 720/hora ‚Üí 17,280/d√≠a

Potenciales leaks:
‚ùå Cierre inadecuado de conexiones HTTP
‚ùå Acumulaci√≥n de m√©tricas sin l√≠mite
‚ùå Event handlers no removidos

Protecciones implementadas:
‚úÖ fetch() usa AbortSignal.timeout(2000) - conexiones no cuelgan
‚úÖ LLMClient maneja activeRequests (contador, no array)
‚úÖ Circuit breaker no acumula historial infinito
‚úÖ dispose() limpia: interval, handlers, referencias
```

**Resultado**: ‚úÖ No hay acumulaci√≥n de memoria detectada

---

### Caso 6: Callbacks en Constructor (Backwards Compatibility)

**Escenario**: C√≥digo legacy crea worker con firma antigua

**Comportamiento**:
```javascript
// Firma antigua (todav√≠a funciona)
new AnalysisWorker(rootPath, {
  onProgress: () => {},
  onComplete: () => {},
  onError: () => {}
});

// Firma nueva (tambi√©n funciona)
new AnalysisWorker(rootPath, 
  { llmService: customService },
  { onProgress: () => {} }
);

// Detecci√≥n autom√°tica en constructor:
if (typeof options === 'function' || options.onProgress || ...) {
  callbacks = options;
  options = {};
}
```

**Resultado**: ‚úÖ Ambas firmas funcionan, c√≥digo legacy no se rompe

---

### Caso 7: Cach√© Compartido vs Por-Instancia

**Escenario**: M√∫ltiples LLMAnalyzer con diferentes cach√©s

**Problema anterior**:
```javascript
// ANTES: Cada analyzer ten√≠a su propia cach√©
Orchestrator.llmAnalyzer.cache = orchestrator.cache;
Worker.llmAnalyzer.cache = ???  // Cach√© diferente
```

**Soluci√≥n actual**:
```javascript
// AHORA: Un solo LLMClient, cache gestionado por worker/analyzer
LLMService.client ‚Üí HTTP client (stateless)
Analyzer.llmAnalyzer.analyzeMultiple() ‚Üí Usa cach√© pasada por par√°metro
```

**Resultado**: ‚úÖ Cache consistency mejorada

---

## 3. PUNTOS DE FALLO IDENTIFICADOS

### üî¥ Cr√≠ticos (Mitigados)

| Punto | Riesgo | Mitigaci√≥n |
|-------|--------|------------|
| GPU no disponible | Alto | Fallback a an√°lisis est√°tico, retry autom√°tico |
| Circuit breaker OPEN | Medio | Transici√≥n a HALF_OPEN despu√©s de 30s |
| Timeout de LLM | Medio | 120s timeout, backoff exponencial en analyzer |

### üü° Medios (Aceptables)

| Punto | Riesgo | Estado |
|-------|--------|--------|
| Health check interval 5s | Bajo | Consume recursos m√≠nimos, configurable |
| M√©tricas en memoria | Bajo | L√≠mite impl√≠cito por contadores |
| Event handlers | Bajo | Se limpian en dispose() |

### üü¢ Bajo (Controlados)

| Punto | Riesgo | Estado |
|-------|--------|--------|
| Import cycles | Bajo | No se detectaron ciclos |
| Singleton reset | Bajo | Solo para tests |
| Backwards compatibility | Bajo | Firma dual soportada |

---

## 4. VALIDACI√ìN DE IMPORTS

### Grafo de Dependencias

```
src/services/llm-service.js
  ‚îú‚îÄ‚îÄ ../ai/llm/client.js ‚úÖ
  ‚îú‚îÄ‚îÄ ../ai/llm/load-config.js ‚úÖ
  ‚îî‚îÄ‚îÄ ../utils/logger.js ‚úÖ

src/core/analysis-worker.js
  ‚îú‚îÄ‚îÄ ../services/llm-service.js ‚úÖ
  ‚îú‚îÄ‚îÄ ../layer-a-static/indexer.js ‚úÖ
  ‚îî‚îÄ‚îÄ ... (otros)

src/core/orchestrator/lifecycle.js
  ‚îú‚îÄ‚îÄ ../services/llm-service.js ‚úÖ
  ‚îú‚îÄ‚îÄ ../analysis-worker.js ‚úÖ
  ‚îî‚îÄ‚îÄ ... (otros)

src/core/orchestrator/llm-analysis.js
  ‚îú‚îÄ‚îÄ ../../services/llm-service.js ‚úÖ
  ‚îî‚îÄ‚îÄ ... (otros)
```

**Ciclos detectados**: Ninguno ‚úÖ

---

## 5. M√âTRICAS Y OBSERVABILIDAD

### M√©tricas Disponibles

```javascript
LLMService.getMetrics() ‚Üí {
  requestsTotal: number,
  requestsSuccessful: number,
  requestsFailed: number,
  latencyMsTotal: number,
  latencyMsAvg: number,
  errorsByType: object,
  lastError: Error,
  lastErrorTime: timestamp,
  availability: boolean,
  circuitBreakerState: 'CLOSED'|'OPEN'|'HALF_OPEN'
}
```

### Eventos

```javascript
llmService.on('available', ({ health }) => {});
llmService.on('unavailable', ({ health }) => {});
llmService.on('error', ({ error, circuitBreakerOpen }) => {});
```

### Logs Estructurados

- `Initializing LLMService...`
- `LLMService initialized (available: true/false)`
- `Health checking started/stopped`
- `Circuit breaker transitioning to OPEN/HALF_OPEN/CLOSED`
- `LLM is now available/no longer available`

---

## 6. RECOMENDACIONES

### Inmediatas (Opcional)

1. **Reducir verbosidad de logs** en health checking (loguear solo cambios de estado)
2. **Agregar m√©trica de throughput** (requests/minuto)
3. **Exportar m√©tricas** en formato Prometheus/StatsD

### Futuras (Mejoras)

1. **Retry con jitter** para evitar thundering herd
2. **Rate limiting** por cliente/worker
3. **Dead letter queue** para jobs fallidos
4. **Health check adaptativo** (intervalo din√°mico basado en estabilidad)

---

## 7. CONCLUSI√ìN

### Estado General: ‚úÖ ROBUSTO

| Aspecto | Estado | Notas |
|---------|--------|-------|
| Inicializaci√≥n | ‚úÖ | Singleton funciona, lazy loading correcto |
| Concurrencia | ‚úÖ | 2 workers comparten servicio sin conflictos |
| Resiliencia | ‚úÖ | Circuit breaker, retries, fallback |
| Memoria | ‚úÖ | No leaks detectados, cleanup apropiado |
| Backwards Compat | ‚úÖ | Firma dual soportada |
| Observabilidad | ‚úÖ | M√©tricas, logs, eventos |

### Pr√≥ximos Pasos

1. **Monitorear en producci√≥n** - Ver m√©tricas reales bajo carga
2. **Ajustar thresholds** - Circuit breaker threshold (5) y timeout (30s) basado en datos reales
3. **Documentar troubleshooting** - Gu√≠a de diagn√≥stico basada en m√©tricas

---

**Validado por**: An√°lisis est√°tico + Simulaci√≥n + Arquitectura Validator  
**Fecha**: 2026-02-14  
**Versi√≥n**: 1.0.0-llm-service-refactor
